#!/usr/bin/env python3
"""
ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import json
from datetime import datetime

# æœ€å°é™ã®RSSãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆä¾å­˜é–¢ä¿‚ãªã—ï¼‰
try:
    import urllib.request
    import xml.etree.ElementTree as ET
    from urllib.parse import urljoin
except ImportError as e:
    print(f"âŒ å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒä¸è¶³: {e}")
    sys.exit(1)

def parse_rss_feed(feed_url, source_name):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’è§£æž"""
    print(f"ðŸ“¡ {source_name} ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
    
    try:
        headers = {
            'User-Agent': 'CryptoMediaSystem/1.0 (+https://crypto-dictionary.net)'
        }
        
        request = urllib.request.Request(feed_url, headers=headers)
        
        with urllib.request.urlopen(request, timeout=30) as response:
            content = response.read().decode('utf-8')
            
        # XMLã‚’ãƒ‘ãƒ¼ã‚¹
        root = ET.fromstring(content)
        
        # RSS 2.0 å½¢å¼ã‚’æƒ³å®š
        items = []
        
        # channelã¾ãŸã¯rssã®ä¸‹ã®itemã‚’æŽ¢ã™
        for item in root.findall('.//item'):
            title_elem = item.find('title')
            link_elem = item.find('link')
            description_elem = item.find('description')
            pubdate_elem = item.find('pubDate')
            
            if title_elem is not None and link_elem is not None:
                title = title_elem.text or ""
                link = link_elem.text or ""
                description = description_elem.text or "" if description_elem is not None else ""
                pubdate = pubdate_elem.text or "" if pubdate_elem is not None else ""
                
                # ä»®æƒ³é€šè²¨é–¢é€£ã‹ãƒã‚§ãƒƒã‚¯
                if is_crypto_related(title, description):
                    items.append({
                        'title': title.strip(),
                        'url': link.strip(),
                        'description': description.strip()[:300],
                        'source': source_name,
                        'pubdate': pubdate,
                        'importance_score': calculate_importance(title, description)
                    })
        
        print(f"âœ… {source_name}: {len(items)}ä»¶ã®ä»®æƒ³é€šè²¨é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
        return items
        
    except Exception as e:
        print(f"âŒ {source_name} ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def is_crypto_related(title, description):
    """ä»®æƒ³é€šè²¨é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ãƒã‚§ãƒƒã‚¯"""
    text = (title + " " + description).lower()
    
    crypto_keywords = [
        'bitcoin', 'btc', 'ethereum', 'eth', 'crypto', 'cryptocurrency',
        'blockchain', 'defi', 'nft', 'altcoin', 'trading', 'exchange',
        'ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³', 'ä»®æƒ³é€šè²¨', 'æš—å·è³‡ç”£', 'ã‚¤ãƒ¼ã‚µãƒªã‚¢ãƒ ', 'ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³'
    ]
    
    return any(keyword in text for keyword in crypto_keywords)

def calculate_importance(title, description):
    """é‡è¦åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    text = (title + " " + description).lower()
    score = 0
    
    # åŸºæœ¬ã‚¹ã‚³ã‚¢ï¼ˆä»®æƒ³é€šè²¨é–¢é€£ãªã‚‰æœ€ä½Ž30ç‚¹ï¼‰
    score = 30
    
    # è¶…é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé«˜ã‚¹ã‚³ã‚¢ï¼‰
    high_impact_keywords = {
        'breaking': 25, 'urgent': 25, 'alert': 20,
        'crash': 20, 'surge': 18, 'soar': 18, 'plunge': 20,
        'record': 15, 'ath': 15, 'all-time high': 15,
        'sec approves': 20, 'sec approval': 20, 'etf': 18,
        'regulation': 15, 'government': 12, 'ban': 18,
        'hack': 15, 'hacked': 15, 'exploit': 12,
        'partnership': 12, 'acquisition': 15, 'merger': 15
    }
    
    # äººæ°—é€šè²¨ï¼ˆæ—¥æœ¬ã§æ³¨ç›®åº¦é«˜ã„ï¼‰
    popular_coins = {
        'bitcoin': 15, 'btc': 15, 'ethereum': 12, 'eth': 12,
        'xrp': 10, 'ripple': 10, 'ada': 8, 'cardano': 8,
        'sol': 10, 'solana': 10, 'doge': 8, 'dogecoin': 8
    }
    
    # ä¾¡æ ¼é–¢é€£ï¼ˆæ—¥æœ¬äººæŠ•è³‡å®¶ãŒæœ€ã‚‚é–¢å¿ƒã‚’æŒã¤ï¼‰
    price_keywords = {
        'price': 12, '$': 8, 'hits': 10, 'reaches': 8,
        'rally': 10, 'pump': 10, 'dump': 12, 'correction': 8,
        'bull': 8, 'bear': 8, 'market': 6
    }
    
    # æ©Ÿé–¢æŠ•è³‡ãƒ»ä¼æ¥­é–¢é€£
    institutional_keywords = {
        'institutional': 12, 'fund': 10, 'investment': 8,
        'corporate': 10, 'treasury': 12, 'adoption': 10,
        'microstrategy': 15, 'tesla': 15, 'blackrock': 18
    }
    
    # DeFiãƒ»æŠ€è¡“é–¢é€£
    tech_keywords = {
        'defi': 8, 'yield': 6, 'staking': 8, 'protocol': 6,
        'upgrade': 8, 'fork': 8, 'consensus': 6, 'layer': 6
    }
    
    # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ã‚¹ã‚³ã‚¢åŠ ç®—
    for keyword, points in high_impact_keywords.items():
        if keyword in text:
            score += points
    
    for keyword, points in popular_coins.items():
        if keyword in text:
            score += points
    
    for keyword, points in price_keywords.items():
        if keyword in text:
            score += points
    
    for keyword, points in institutional_keywords.items():
        if keyword in text:
            score += points
    
    for keyword, points in tech_keywords.items():
        if keyword in text:
            score += points
    
    # è¤‡æ•°ã®é‡è¦è¦ç´ ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒœãƒ¼ãƒŠã‚¹
    important_count = sum(1 for category in [high_impact_keywords, popular_coins, price_keywords, institutional_keywords] 
                         for keyword in category if keyword in text)
    if important_count >= 3:
        score += 10  # è¤‡æ•°è¦ç´ ãƒœãƒ¼ãƒŠã‚¹
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã«é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯ãƒœãƒ¼ãƒŠã‚¹
    title_lower = title.lower()
    if any(keyword in title_lower for keyword in ['bitcoin', 'btc', 'ethereum', 'eth', 'breaking', 'surge', 'crash']):
        score += 5
    
    return min(score, 100)

def collect_crypto_news():
    """ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åŽé›†"""
    
    # ä¸»è¦ãªRSSãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆé«˜å“è³ªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ï¼‰
    rss_feeds = {
        'CoinDesk': 'https://www.coindesk.com/arc/outboundfeeds/rss/',
        'CoinTelegraph': 'https://cointelegraph.com/rss',
        'Decrypt': 'https://decrypt.co/feed',
        'TheBlock': 'https://www.theblock.co/rss.xml',
        'CryptoSlate': 'https://cryptoslate.com/feed/',
        'U.Today': 'https://u.today/rss',
        'BeInCrypto': 'https://beincrypto.com/feed/'
    }
    
    all_news = []
    
    print("ðŸš€ ä»®æƒ³é€šè²¨ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†é–‹å§‹")
    print("=" * 50)
    
    for source_name, feed_url in rss_feeds.items():
        news_items = parse_rss_feed(feed_url, source_name)
        all_news.extend(news_items)
    
    # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆ
    all_news.sort(key=lambda x: x['importance_score'], reverse=True)
    
    print("\n" + "=" * 50)
    print(f"ðŸ“Š åˆè¨ˆ {len(all_news)} ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åŽé›†")
    
    # ãƒˆãƒƒãƒ—10ã‚’è¡¨ç¤º
    print("\nðŸ”¥ é‡è¦åº¦ä¸Šä½ãƒ‹ãƒ¥ãƒ¼ã‚¹:")
    for i, news in enumerate(all_news[:10], 1):
        print(f"{i:2d}. [{news['source']}] {news['title'][:60]}{'...' if len(news['title']) > 60 else ''}")
        print(f"    é‡è¦åº¦: {news['importance_score']:.1f}/100")
        print(f"    URL: {news['url']}")
        print()
    
    return all_news

def save_news_data(news_items):
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"collected_news_{timestamp}.json"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'total_count': len(news_items),
                'news_items': news_items
            }, f, ensure_ascii=False, indent=2)
        
        print(f"ðŸ’¾ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filename}")
        return filename
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return None

if __name__ == "__main__":
    try:
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†å®Ÿè¡Œ
        news_data = collect_crypto_news()
        
        if news_data:
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            saved_file = save_news_data(news_data)
            
            print("\nðŸŽ‰ ãƒ‹ãƒ¥ãƒ¼ã‚¹åŽé›†å®Œäº†ï¼")
            print(f"æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: ã“ã‚Œã‚‰ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆã§ãã¾ã™")
            
            # è¨˜äº‹ç”Ÿæˆã®æº–å‚™ãŒã§ãã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¡¨ç¤º
            high_priority_news = [n for n in news_data if n['importance_score'] >= 70]
            medium_priority_news = [n for n in news_data if 50 <= n['importance_score'] < 70]
            
            print(f"\nðŸ“ é«˜å„ªå…ˆåº¦è¨˜äº‹ï¼ˆ70ç‚¹ä»¥ä¸Šï¼‰: {len(high_priority_news)}ä»¶")
            print(f"ðŸ“ ä¸­å„ªå…ˆåº¦è¨˜äº‹ï¼ˆ50-69ç‚¹ï¼‰: {len(medium_priority_news)}ä»¶")
            
            if high_priority_news:
                print("\nðŸ”¥ é«˜å„ªå…ˆåº¦ãƒ‹ãƒ¥ãƒ¼ã‚¹:")
                for i, news in enumerate(high_priority_news[:5], 1):
                    print(f"  {i}. [{news['source']}] {news['title'][:80]}...")
                    print(f"     é‡è¦åº¦: {news['importance_score']:.1f}/100")
            
            total_quality_news = len(high_priority_news) + len(medium_priority_news)
            print(f"\nâœ¨ åˆè¨ˆ {total_quality_news} ä»¶ã®é«˜å“è³ªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åŽé›†ã—ã¾ã—ãŸï¼")
            
        else:
            print("âŒ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)